{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.iforest import IsolationForest\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, f1_score\n",
    "from util.utils import find_TPR_threshold\n",
    "from sklearn.ensemble import IsolationForest as skIsolationForest\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from data.cicids import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing the data...\n",
      "Data preprocessing done.\n",
      "\n",
      "Dataset: Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "Dataset shape: (225745, 70)\n",
      "Benign samples: 97718\n",
      "Anomalies in dataset: 128027\n",
      "Contamination rate: 56.7131 %\n",
      "\n",
      "Preprocessing the data...\n",
      "Data preprocessing done.\n",
      "\n",
      "Dataset: Wednesday-workingHours.pcap_ISCX.csv\n",
      "Dataset shape: (692703, 70)\n",
      "Benign samples: 440031\n",
      "Anomalies in dataset: 252672\n",
      "Contamination rate: 36.4762 %\n",
      "\n",
      "Preprocessing the data...\n",
      "Data preprocessing done.\n",
      "\n",
      "Dataset: Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
      "Dataset shape: (170366, 70)\n",
      "Benign samples: 168186\n",
      "Anomalies in dataset: 2180\n",
      "Contamination rate: 1.2796 %\n",
      "\n",
      "Preprocessing the data...\n",
      "Data preprocessing done.\n",
      "\n",
      "Dataset: Tuesday-WorkingHours.pcap_ISCX.csv\n",
      "Dataset shape: (445909, 70)\n",
      "Benign samples: 432074\n",
      "Anomalies in dataset: 13835\n",
      "Contamination rate: 3.1027 %\n",
      "\n",
      "Preprocessing the data...\n",
      "Data preprocessing done.\n",
      "\n",
      "Dataset: Monday-WorkingHours.pcap_ISCX.csv\n",
      "Dataset shape: (529918, 70)\n",
      "Benign samples: 529918\n",
      "Anomalies in dataset: 0\n",
      "Contamination rate: 0.0000 %\n",
      "\n",
      "Preprocessing the data...\n",
      "Data preprocessing done.\n",
      "\n",
      "Dataset: Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
      "Dataset shape: (288602, 70)\n",
      "Benign samples: 288566\n",
      "Anomalies in dataset: 36\n",
      "Contamination rate: 0.0125 %\n",
      "\n",
      "Preprocessing the data...\n",
      "Data preprocessing done.\n",
      "\n",
      "Dataset: Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
      "Dataset shape: (191033, 70)\n",
      "Benign samples: 189067\n",
      "Anomalies in dataset: 1966\n",
      "Contamination rate: 1.0291 %\n",
      "\n",
      "Preprocessing the data...\n",
      "Data preprocessing done.\n",
      "\n",
      "Dataset: Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "Dataset shape: (286467, 70)\n",
      "Benign samples: 127537\n",
      "Anomalies in dataset: 158930\n",
      "Contamination rate: 55.4793 %\n",
      "\n",
      "Complete dataset shape: (2830743, 70)\n",
      "Benign samples: 2273097\n",
      "Anomalies in dataset: 557646\n",
      "Contamination rate: 19.6996 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "filenames = os.listdir('../datasets/CIC-IDS-17')\n",
    "datasets = []\n",
    "for filename in filenames:\n",
    "    data = pd.read_csv(f'../datasets/CIC-IDS-17/{filename}')\n",
    "    data = preprocess(data)\n",
    "\n",
    "    X = data.drop(' Label', axis=1)\n",
    "    y = pd.Series([0 if x == 'BENIGN' else 1 for x in data[' Label']])\n",
    "    datasets.append((X, y, filename))\n",
    "\n",
    "    print(f'Dataset: {filename}')\n",
    "    print(f'Dataset shape: {X.shape}')\n",
    "    print(f'Benign samples: {y.value_counts()[0]}')\n",
    "    print(f'Anomalies in dataset: {y.value_counts().get(1, 0)}')\n",
    "    print(f'Contamination rate: {y.value_counts().get(1, 0) / y.count() * 100:.4f} %\\n')\n",
    "\n",
    "complete_dataset = (pd.concat([x[0] for x in datasets]), pd.concat([x[1] for x in datasets]))\n",
    "print(f'Complete dataset shape: {complete_dataset[0].shape}')\n",
    "print(f'Benign samples: {complete_dataset[1].value_counts()[0]}')\n",
    "print(f'Anomalies in dataset: {complete_dataset[1].value_counts().get(1, 0)}')\n",
    "print(f'Contamination rate: {complete_dataset[1].value_counts().get(1, 0) / complete_dataset[1].count() * 100:.4f} %\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Isolation Forest\n",
    "clf_forests = []\n",
    "sample_size = 50000\n",
    "n_trees = 300\n",
    "for X, y, filename in datasets:\n",
    "    print(f'Training Isolation Forest on {filename}')\n",
    "    clf = IsolationForest(sample_size, n_trees)\n",
    "    start_time = time.time()\n",
    "    clf.fit(X, improved=False)\n",
    "    clf_forests.append((clf, filename))\n",
    "    end_time = time.time()\n",
    "    print(f'{sample_size=}, {n_trees=}, training time: {end_time - start_time:.3f}s\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for (clf, filename), (X, y, _) in zip(clf_forests, datasets):\n",
    "    print(f'Predicting on {filename}')\n",
    "    print(f'Dataset shape: {X.shape}')\n",
    "    print(f'Benign samples: {y.value_counts()[0]}')\n",
    "    print(f'Anomalies in dataset: {y.value_counts().get(1, 0)}')\n",
    "    print(f'Contamination rate: {y.value_counts().get(1, 0) / y.count() * 100:.4f} %\\n')\n",
    "    \n",
    "    # Predict\n",
    "    start_time = time.time()\n",
    "    scores = clf.anomaly_score(X)\n",
    "    threshold, FPR = find_TPR_threshold(y, scores, 0.9)\n",
    "    y_pred = clf.predict_from_anomaly_scores(scores, threshold)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Metrics\n",
    "    plt.hist(scores, bins=30, label=f'{filename}')\n",
    "    print(f'Prediction time: {end_time - start_time:.3f}s')\n",
    "    print('Predictions: ')\n",
    "    print(pd.Series(y_pred).value_counts())\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    print(classification_report(y, y_pred))\n",
    "    print(f'ROC AUC: {roc_auc_score(y, y_pred):.4f}')\n",
    "    print(f'F1 Score: {f1_score(y, y_pred):.4f}')\n",
    "    print(f'Threshold: {threshold:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training on complete dataset')\n",
    "print(f'Dataset shape: {complete_dataset.shape}')\n",
    "print(f'Benign samples: {complete_dataset[1].value_counts()[0]}')\n",
    "print(f'Anomalies in dataset: {complete_dataset[1].value_counts().get(1, 0)}')\n",
    "print(f'Contamination rate: {complete_dataset[1].value_counts().get(1, 0) / complete_dataset[1].count() * 100:.4f} %\\n')\n",
    "\n",
    "# Train Isolation Forest\n",
    "clf_complete = IsolationForest(sample_size, n_estimators)\n",
    "start_time = time.time()\n",
    "clf_complete.fit(complete_dataset[0], improved=False)\n",
    "end_time = time.time()\n",
    "print(f'{sample_size=}, {n_estimators=}, training time: {end_time - start_time:.3f}s\\n')\n",
    "\n",
    "print('Predicting on complete dataset')\n",
    "start_time = time.time()\n",
    "scores = clf_complete.anomaly_score(complete_dataset[0])\n",
    "threshold, FPR = find_TPR_threshold(complete_dataset[1], scores, 0.9)\n",
    "y_pred = clf_complete.predict_from_anomaly_scores(scores, threshold)\n",
    "end_time = time.time()\n",
    "\n",
    "# Metrics\n",
    "plt.hist(scores, bins=30, label='Complete dataset')\n",
    "print(f'Prediction time: {end_time - start_time:.3f}s')\n",
    "print('Predictions: ')\n",
    "print(pd.Series(y_pred).value_counts())\n",
    "print(confusion_matrix(complete_dataset[1], y_pred))\n",
    "print(classification_report(complete_dataset[1], y_pred))\n",
    "print(f'ROC AUC: {roc_auc_score(complete_dataset[1], y_pred):.4f}')\n",
    "print(f'F1 Score: {f1_score(complete_dataset[1], y_pred):.4f}')\n",
    "print(f'Threshold: {threshold:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compare with sklearn\n",
    "sk_clf = skIsolationForest(contamination=0.2, n_estimators=100, max_samples=256, n_jobs=-1, random_state=42)\n",
    "start_time = time.time()\n",
    "sk_clf.fit(complete_dataset[0])\n",
    "end_time = time.time()\n",
    "print(f'Sklearn training time: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "sk_scores = sk_clf.decision_function(X).reshape(-1, 1)\n",
    "sk_threshold, sk_FPR = find_TPR_threshold(y, sk_scores, 0.8)\n",
    "sk_y_pred = [1 if score >= sk_threshold else 0 for score in sk_scores]\n",
    "\n",
    "print(f'Confusion matrix: {confusion_matrix(y, sk_y_pred)}')\n",
    "print(f'Classification report: {classification_report(y, sk_y_pred)}')\n",
    "print(f'ROC AUC score: {roc_auc_score(y, sk_y_pred)}')\n",
    "print(f'Threshold: {sk_threshold}')\n",
    "print(f'FPR: {sk_FPR}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
